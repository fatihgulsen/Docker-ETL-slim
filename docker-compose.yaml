version: "1"

######################################################
# COMMONS
######################################################
x-airflow-common:
  &airflow-common
  image: ${AIRFLOW_IMAGE_NAME:-apache/airflow:2.1.2}
  environment:
    &airflow-common-env
    #the other parameters 
    AIRFLOW__CORE__LOGGING_LEVEL: DEBUG #add 


x-sparkworker-common: &sparkworker-common
  restart: always
  build: ./docker/spark
  volumes:
    - ./mnt/spark/work/:/opt/bitnami/spark/work/
    - ./mnt/spark/logs/:/opt/bitnami/spark/history/
    - ./mnt/airflow/dags:/opt/bitnami/airflow/dags
    - ./mnt/spark/scripts/:/opt/bitnami/spark/scripts
    - ./docker/spark/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    - ./docker/spark/log4j.properties:/opt/bitnami/spark/conf/log4j.properties
  depends_on:
    - spark-master
  environment:
    - SPARK_MODE=worker
    - SPARK_MASTER="spark://spark-master:7077"
    - SPARK_WORKLOAD=worker
    - SPARK_RPC_AUTHENTICATION_ENABLED=no
    - SPARK_RPC_ENCRYPTION_ENABLED=no
    - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
    - SPARK_SSL_ENABLED=no
    - SPARK_USER=spark   
  networks:
    - etl-net

services:

######################################################
# DATABASE SERVICE
######################################################

  mssql:
    restart: always
    image: mcr.microsoft.com/mssql/server:2022-latest
    container_name: mssql
    networks:
      etl-net:
        ipv4_address: 10.5.0.100
    ports:
      - 1401:1433
    volumes:
      - ./mnt/mssql/data/:/var/opt/mssql/data
      - ./mnt/mssql/log/:/var/opt/mssql/log
      - ./mnt/mssql/secrets/:/var/opt/mssql/secrets
      - ./mnt/mssql/backup/:/var/opt/mssql/backup
    environment:
      - ACCEPT_EULA=Y
      - MSSQL_SA_PASSWORD=TradeAtlas*

  postgres:
    image: postgres:14-alpine
    container_name: postgres
    restart: always
    ports:
      - 5401:5432
    networks:
      etl-net:
        ipv4_address: 10.5.0.101
    environment:  
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/databases/init_postgres_database.sql:/docker-entrypoint-initdb.d/init_postgresql_database.sql
    logging:
      driver: "json-file"
      options:
          max-file: "5"
          max-size: "10m"
    healthcheck:
      test: [ "CMD", "pg_isready", "-q", "-d", "postgres", "-U", "postgres" ]
      timeout: 45s
      interval: 10s
      retries: 10
      
  redis:
    image: redis:7.2-alpine
    container_name: redis
    restart: always
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    environment:
      - ALLOW_EMPTY_PASSWORD=yes
    networks:
      etl-net:
        ipv4_address: 10.5.0.102

######################################################
# MINIO SERVICE
######################################################

  minio:
    image: docker.io/bitnami/minio:2023
    container_name: minio
    restart: always
    environment:
      - MINIO_ROOT_USER=minio
      - MINIO_ROOT_PASSWORD=miniosecret
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 30s
      timeout: 20s
      retries: 3
    ports:
      - 9000:9000
      - 9001:9001
    volumes:
      - 'minio_data:/bitnami/minio/data'
      - 'minio_certs:/certs'
    networks:
      etl-net:
        ipv4_address: 10.5.0.103

  minio-client:
    image: docker.io/bitnami/minio-client:2023
    user: root
    restart: on-failure
    container_name: minio-client
    depends_on:
      - minio
    networks:
      etl-net:
    environment:
      - MINIO_SERVER_HOST="minio"
      - MINIO_SERVER_ACCESS_KEY="minio"
      - MINIO_SERVER_SECRET_KEY="miniosecret"
    entrypoint: >
      /bin/sh -c "
      mc alias set minio http://minio:9000 minio miniosecret;
      mc mb minio/spark-logs;
      mc mb minio/tmp;
      mc mb minio/airflow-logs;
      mc admin user add minio airflow airflow_secret;
      echo 'Added user airflow.';
      mc admin policy set minio readwrite user=airflow;
      exit 0;
      "

######################################################
# AIRFLOW SERVICES
######################################################

  airflow-scheduler:
    build: ./docker/airflow/airflow-scheduler
    container_name: airflow-scheduler
    restart: always
    environment:
      - AIRFLOW_FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
      - AIRFLOW_SECRET_KEY=a25mQ1FHTUh3MnFRSk5KMEIyVVU2YmN0VGRyYTVXY08=
      - AIRFLOW_DATABASE_HOST=postgres
      - AIRFLOW_DATABASE_NAME=airflow
      - AIRFLOW_DATABASE_USERNAME=airflow
      - AIRFLOW_DATABASE_PASSWORD=airflow
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_WEBSERVER_HOST=airflow
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@10.5.0.101:5432/airflow
      - AIRFLOW__DATABASE__LOAD_DEFAULT_CONNECTIONS=False
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
      - REDIS_HOST=redis
      - AIRFLOW__LOGGING__REMOTE_LOGGING=True
      - AIRFLOW__LOGGING__REMOTE_BASE_LOG_FOLDER=s3://airflow-logs
      - AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID=s3_conn
      - AIRFLOW__LOGGING__ENCRYPT_S3_LOGS=False
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__SECRETS__USE_CACHE=true
      # - AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR
    networks:
      - etl-net
    volumes:
      - ./mnt/airflow/dags:/opt/bitnami/airflow/dags
      - ./mnt/airflow//logs:/opt/bitnami/airflow/logs
      - ./mnt/airflow//plugins:/opt/bitnami/airflow/plugins
      - ./docker/airflow/requirements.txt:/bitnami/python/requirements.txt

    depends_on:
      - minio
      - postgres
      - redis

  airflow-worker:
    build: ./docker/airflow/airflow-worker
    container_name: airflow-worker
    restart: always
    environment:
      - AIRFLOW_FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
      - AIRFLOW_SECRET_KEY=a25mQ1FHTUh3MnFRSk5KMEIyVVU2YmN0VGRyYTVXY08=
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW_DATABASE_HOST=postgres
      - AIRFLOW_DATABASE_NAME=airflow
      - AIRFLOW_DATABASE_USERNAME=airflow
      - AIRFLOW_DATABASE_PASSWORD=airflow
      - AIRFLOW_WEBSERVER_HOST=airflow
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@10.5.0.101:5432/airflow
      - AIRFLOW__DATABASE__LOAD_DEFAULT_CONNECTIONS=False
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
      - REDIS_HOST=redis
      - AIRFLOW__LOGGING__REMOTE_LOGGING=True
      - AIRFLOW__LOGGING__REMOTE_BASE_LOG_FOLDER=s3://airflow-logs
      - AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID=s3_conn
      - AIRFLOW__LOGGING__ENCRYPT_S3_LOGS=False
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__SECRETS__USE_CACHE=true
      # - AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR

    networks:
      - etl-net
    volumes:
      - ./mnt/airflow/dags:/opt/bitnami/airflow/dags
      - ./mnt/airflow/logs:/opt/bitnami/airflow/logs
      - ./mnt/airflow/plugins:/opt/bitnami/airflow/plugins
      - ./docker/airflow/requirements.txt:/bitnami/python/requirements.txt
    depends_on:
      - minio
      - postgres
      - redis

  airflow:
    build: ./docker/airflow/airflow-master
    container_name: airflow
    restart: always

    environment:
      - AIRFLOW_FERNET_KEY=46BKJoQYlPPOexq0OhDZnIlNepKFf87WFwLbfzqDDho=
      - AIRFLOW_SECRET_KEY=a25mQ1FHTUh3MnFRSk5KMEIyVVU2YmN0VGRyYTVXY08=
      - AIRFLOW_DATABASE_HOST=postgres
      - AIRFLOW_DATABASE_NAME=airflow
      - AIRFLOW_DATABASE_USERNAME=airflow
      - AIRFLOW_DATABASE_PASSWORD=airflow
      - AIRFLOW_PASSWORD=airflow
      - AIRFLOW_USERNAME=airflow
      - AIRFLOW_EMAIL=user@example.com
      - AIRFLOW_EXECUTOR=CeleryExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@10.5.0.101:5432/airflow
      - AIRFLOW__DATABASE__LOAD_DEFAULT_CONNECTIONS=False
      - AIRFLOW__WEBSERVER__EXPOSE_CONFIG=True
      - REDIS_HOST=redis
      - AIRFLOW__LOGGING__REMOTE_LOGGING=True
      - AIRFLOW__LOGGING__REMOTE_BASE_LOG_FOLDER=s3://airflow-logs
      - AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID=s3_conn
      - AIRFLOW__LOGGING__ENCRYPT_S3_LOGS=False
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__SECRETS__USE_CACHE=true
      # - AIRFLOW__LOGGING__LOGGING_LEVEL=ERROR

    networks:
      - etl-net
    ports:
      - '8080:8080'
    volumes:
      - ./mnt/airflow/dags:/opt/bitnami/airflow/dags
      - ./mnt/airflow//logs:/opt/bitnami/airflow/logs
      - ./mnt/airflow//plugins:/opt/bitnami/airflow/plugins
      - ./docker/airflow/requirements.txt:/bitnami/python/requirements.txt
    depends_on:
      - minio
      - postgres
      - redis

######################################################
# SPARK SERVICE
######################################################

  spark-master:
    build: ./docker/spark
    container_name: spark-master
    restart: always
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_USER=spark
    ports:
      - '4040:8080'
    volumes:
      - ./mnt/spark/work/:/opt/bitnami/spark/work/
      - ./mnt/spark/logs/:/opt/bitnami/spark/history/
      - ./mnt/spark/scripts/:/opt/bitnami/spark/scripts
      - ./mnt/airflow/dags:/opt/bitnami/airflow/dags
      - ./docker/spark/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ./docker/spark/log4j.properties:/opt/bitnami/spark/conf/log4j.properties
    depends_on:
      - minio
    networks:
      - etl-net

  spark-worker-1:
    <<: *sparkworker-common
    container_name: spark-worker-1

  spark-worker-2:
    <<: *sparkworker-common
    container_name: spark-worker-2

######################################################
# NETWORKS
######################################################

networks:
  etl-net:
    name: etl
    ipam:
      config:
        - subnet: 10.5.0.0/16
          gateway: "10.5.0.1"
    driver: bridge

######################################################
# VOLUMES
######################################################

volumes:
  minio_data:
    driver: local
  minio_certs:
    driver: local
  redis_data:
    driver: local
  postgres_data:
    driver: local